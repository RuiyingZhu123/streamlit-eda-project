{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "## Phase 2: Data Quality Assessment\n",
    "\n",
    "### Motivation\n",
    "Whatâ€™s broken, missing, or suspicious?\n",
    "\n",
    "### Questions to answer\n",
    "1. Are types correct for each variable?\n",
    "2. Do values make domain sense?\n",
    "3. Where is data missing, and how much?\n",
    "4. Are there duplicates?\n",
    "5. Are there outliers?\n",
    "6. Can I trust this data as-is?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('../data/raw/amazon_sales_2025_INR.csv',\n",
    "                 parse_dates=['Date'],\n",
    "                 na_values=[\"NA\", \"\", \"null\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "**Interpretation**\n",
    "\n",
    "Date is correctly parsed as datetime. \n",
    "Numeric fields: Quantity, Unit_Price_INR, Total_Sales_INR, Review_Rating \n",
    "Categorical fields Product_Category, State, Payment_Method, etc. they appear as object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "**Interpretation**\n",
    "After verifying using `.isna().sum()`, no missing values were found across the dataset. Therefore, no further action on missing data is required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "**Interpretation**\n",
    "  \n",
    "There are no repeated rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Quantity'].describe()\n",
    "df[~df['Quantity'].between(1, 5)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "**Interpretation**\n",
    "\n",
    "For Quantity variable, the range is between 1-5, which make sense and no values outside 1-5 this is good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Review_Rating'].unique()\n",
    "df[~df['Review_Rating'].between(1, 5)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "**Interpretation**\n",
    "\n",
    "Also, no values outside 1-5 this is good. And the number identification is understandable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['Unit_Price_INR'] <= 0]\n",
    "df[df['Total_Sales_INR'] <= 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "**Interpretation**\n",
    "\n",
    "All values fall into a realistic market range. Both prices and sales > 0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Product_Category'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Payment_Method'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Delivery_Status'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['State'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "**Interpretation**\n",
    "1. Product_Category, Payment_method and delivery_status have limited categories. They are good for grouping.\n",
    "2. States come with number 28 means 28 Indian States, which is reasonable.\n",
    "3. There are no strange category values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['unitprice_z'] = (df['Unit_Price_INR'] - df['Unit_Price_INR'].mean()) / df['Unit_Price_INR'].std()\n",
    "df['sales_z'] = (df['Total_Sales_INR'] - df['Total_Sales_INR'].mean()) / df['Total_Sales_INR'].std()\n",
    "\n",
    "df[(df['unitprice_z'].abs() > 3) | (df['sales_z'].abs() > 3)].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "**Explanation**\n",
    "\n",
    "The dataset reviewed from z-score means it doesn't contain statistical outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1 = df['Total_Sales_INR'].quantile(0.25)\n",
    "Q3 = df['Total_Sales_INR'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "outliers = df[(df['Total_Sales_INR'] < Q1 - 1.5*IQR) |\n",
    "              (df['Total_Sales_INR'] > Q3 + 1.5*IQR)]\n",
    "outliers.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Total_Sales_INR'].plot(kind='box', figsize=(5,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "**Explanation**\n",
    "\n",
    "To identify outliers, I applied IQR method, especially for total_sales_INR.The filtered results show 6 transactions with significantly higher sales amounts. These outliers come from categories such as home & kitchen, clothing, books and electronics. There are no negative values appear and the date and customer ID variables look normal. \n",
    "Therefore, even though there are outliers, it doesn't mean there are data quality issues requiring removal for those transactions.     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1 = df['Unit_Price_INR'].quantile(0.25)\n",
    "Q3 = df['Unit_Price_INR'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "outliers = df[(df['Unit_Price_INR'] < Q1 - 1.5*IQR) |\n",
    "              (df['Unit_Price_INR'] > Q3 + 1.5*IQR)]\n",
    "outliers.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "**Explanation**\n",
    "\n",
    "There are no outliers in Unit_Price_INR column."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "## Conclusion:\n",
    "\n",
    "Even though there are 0 missing values, but as the initial step in phase 1, there are no missing categories or incomplete price or quantity fields. Also all the customer id is unique. The data is well structured with no wrong dtypes. I can not find any impossible or invalid values so far and all values fall into realistic business range. The outliers appeared but it's real high-value transactions so it's reasonable.Furthermore, the dataset not have duplicates. \n",
    "Therefore, I assume the dataset can be trusted as-is for analysis.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "### Hypothesis Generation\n",
    "1. For outliers in Total_Sales_INR, it might caused from premium items. Those numbers are reasonable because the Date and Customer ID fields show normally.\n",
    "2. The dataset assume has no missing values based on recent check and missing values assume be cleaned by provider. \n",
    "3. All categorical and numerical variables fall within reasonable domains.\n",
    "### Iteration Signals:\n",
    "We may need to verify whether these extreme values are expected business behavior or not. Also, because the dataset contains no missing values, there is no need to revisit data loading parameters or investigate data loss. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
